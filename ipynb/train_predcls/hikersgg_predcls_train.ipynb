{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:42.695708Z",
     "iopub.status.busy": "2024-04-23T07:55:42.695388Z",
     "iopub.status.idle": "2024-04-23T07:55:42.720832Z",
     "shell.execute_reply": "2024-04-23T07:55:42.720225Z",
     "shell.execute_reply.started": "2024-04-23T07:55:42.695663Z"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "codebase = '/output/HiKER-SGG/'\n",
    "sys.path.append(\"/output/HiKER-SGG/\")\n",
    "# sys.path.append('../../../')\n",
    "# sys.path.append('../../../apex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:42.722683Z",
     "iopub.status.busy": "2024-04-23T07:55:42.722429Z",
     "iopub.status.idle": "2024-04-23T07:55:43.555512Z",
     "shell.execute_reply": "2024-04-23T07:55:43.555034Z",
     "shell.execute_reply.started": "2024-04-23T07:55:42.722661Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:43.556305Z",
     "iopub.status.busy": "2024-04-23T07:55:43.556110Z",
     "iopub.status.idle": "2024-04-23T07:55:43.567934Z",
     "shell.execute_reply": "2024-04-23T07:55:43.567391Z",
     "shell.execute_reply.started": "2024-04-23T07:55:43.556290Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_name = 'hikersgg_predcls_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:43.568679Z",
     "iopub.status.busy": "2024-04-23T07:55:43.568518Z",
     "iopub.status.idle": "2024-04-23T07:55:45.376585Z",
     "shell.execute_reply": "2024-04-23T07:55:45.375826Z",
     "shell.execute_reply.started": "2024-04-23T07:55:43.568665Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time as time_time\n",
    "import numpy as np\n",
    "# from torch import optim\n",
    "from apex import amp\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "write = tqdm.write\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from config import ModelConfig, BOX_SCALE, IM_SCALE\n",
    "from torch.nn import functional as F\n",
    "from lib.pytorch_misc import optimistic_restore, de_chunkize, clip_grad_norm\n",
    "from lib.evaluation.sg_eval import BasicSceneGraphEvaluator, calculate_mR_from_evaluator_list, eval_entry\n",
    "from lib.pytorch_misc import print_para\n",
    "from dataloaders.visual_genome import VGDataLoader, VG\n",
    "\n",
    "from lib.my_model_24 import KERN\n",
    "\n",
    "# sg val\n",
    "# import numpy\n",
    "# import pyximport\n",
    "# pyximport.install(setup_args={\"script_args\":[\"--compiler=mingw32\"],\n",
    "#                               \"include_dirs\":numpy.get_include()},\n",
    "#                   reload_support=True)\n",
    "# then delete \"script_args\":[\"--compiler=mingw32\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:45.377974Z",
     "iopub.status.busy": "2024-04-23T07:55:45.377574Z",
     "iopub.status.idle": "2024-04-23T07:55:45.402312Z",
     "shell.execute_reply": "2024-04-23T07:55:45.401718Z",
     "shell.execute_reply.started": "2024-04-23T07:55:45.377956Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = ModelConfig(f'''\n",
    "-m predcls -p 2500 -clip 5\n",
    "-tb_log_dir ../data/summaries/kern_predcls/{exp_name}\n",
    "-save_dir ../data/checkpoints/kern_predcls/{exp_name}\n",
    "-ckpt ../data/checkpoints/vgdet/vgrel-11.tar\n",
    "-val_size 5000\n",
    "-adam\n",
    "-b 3\n",
    "-ngpu 1\n",
    "-lr 1e-4\n",
    "''')\n",
    "# lr 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:45.403151Z",
     "iopub.status.busy": "2024-04-23T07:55:45.402996Z",
     "iopub.status.idle": "2024-04-23T07:55:45.425490Z",
     "shell.execute_reply": "2024-04-23T07:55:45.424845Z",
     "shell.execute_reply.started": "2024-04-23T07:55:45.403137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modified\n",
    "conf.MODEL.CONF_MAT_FREQ_TRAIN = '/output/data/misc/conf_mat_freq_train.npy'\n",
    "conf.MODEL.LRGA.USE_LRGA = False\n",
    "conf.MODEL.USE_ONTOLOGICAL_ADJUSTMENT = False\n",
    "conf.MODEL.NORMALIZE_EOA = False\n",
    "conf.num_workers = 9\n",
    "# conf.MODEL.LRGA.K = 50\n",
    "# conf.MODEL.LRGA.DROPOUT = 0.5\n",
    "# conf.MODEL.GN.NUM_GROUPS = 1024//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:45.427605Z",
     "iopub.status.busy": "2024-04-23T07:55:45.427441Z",
     "iopub.status.idle": "2024-04-23T07:55:45.448229Z",
     "shell.execute_reply": "2024-04-23T07:55:45.447657Z",
     "shell.execute_reply.started": "2024-04-23T07:55:45.427590Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:45.448828Z",
     "iopub.status.busy": "2024-04-23T07:55:45.448686Z",
     "iopub.status.idle": "2024-04-23T07:55:49.884107Z",
     "shell.execute_reply": "2024-04-23T07:55:49.883351Z",
     "shell.execute_reply.started": "2024-04-23T07:55:45.448815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For evaluating the confusion matrix\n",
    "train_full, val, test = VG.splits(num_val_im=conf.val_size, filter_duplicate_rels=True,\n",
    "                            use_proposals=conf.use_proposals,\n",
    "                            filter_non_overlap=conf.mode == 'sgdet', with_clean_classifier=False, get_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:49.885115Z",
     "iopub.status.busy": "2024-04-23T07:55:49.884942Z",
     "iopub.status.idle": "2024-04-23T07:55:49.908747Z",
     "shell.execute_reply": "2024-04-23T07:55:49.908172Z",
     "shell.execute_reply.started": "2024-04-23T07:55:49.885100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, train_full_loader = VGDataLoader.splits(train_full, train_full, mode='rel',\n",
    "                                               batch_size=conf.batch_size,\n",
    "                                               num_workers=conf.num_workers,\n",
    "                                               num_gpus=conf.num_gpus,\n",
    "                                               pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:49.909540Z",
     "iopub.status.busy": "2024-04-23T07:55:49.909378Z",
     "iopub.status.idle": "2024-04-23T07:55:54.634795Z",
     "shell.execute_reply": "2024-04-23T07:55:54.633974Z",
     "shell.execute_reply.started": "2024-04-23T07:55:49.909526Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, val, test = VG.splits(num_val_im=conf.val_size, filter_duplicate_rels=True,\n",
    "                            use_proposals=conf.use_proposals,\n",
    "                            filter_non_overlap=conf.mode == 'sgdet', with_clean_classifier=True, get_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:54.635864Z",
     "iopub.status.busy": "2024-04-23T07:55:54.635685Z",
     "iopub.status.idle": "2024-04-23T07:55:54.661265Z",
     "shell.execute_reply": "2024-04-23T07:55:54.660680Z",
     "shell.execute_reply.started": "2024-04-23T07:55:54.635846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind_to_predicates = train.ind_to_predicates # ind_to_predicates[0] means no relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:54.662195Z",
     "iopub.status.busy": "2024-04-23T07:55:54.662032Z",
     "iopub.status.idle": "2024-04-23T07:55:54.679660Z",
     "shell.execute_reply": "2024-04-23T07:55:54.679155Z",
     "shell.execute_reply.started": "2024-04-23T07:55:54.662181Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = VGDataLoader.splits(train, val, mode='rel',\n",
    "                                               batch_size=conf.batch_size,\n",
    "                                               num_workers=conf.num_workers,\n",
    "                                               num_gpus=conf.num_gpus,\n",
    "                                               pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:55:54.680460Z",
     "iopub.status.busy": "2024-04-23T07:55:54.680304Z",
     "iopub.status.idle": "2024-04-23T07:56:00.325606Z",
     "shell.execute_reply": "2024-04-23T07:56:00.324800Z",
     "shell.execute_reply.started": "2024-04-23T07:55:54.680446Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "detector = KERN(classes=train.ind_to_classes, rel_classes=train.ind_to_predicates,\n",
    "                num_gpus=conf.num_gpus, mode=conf.mode, require_overlap_det=True,\n",
    "                use_resnet=conf.use_resnet, use_proposals=conf.use_proposals, pooling_dim=conf.pooling_dim,\n",
    "                ggnn_rel_time_step_num=3, ggnn_rel_hidden_dim=1024, ggnn_rel_output_dim=None,\n",
    "                # 这三个参数是什么？\n",
    "                graph_path=os.path.join(codebase, 'graphs/005/all_edges_with_sccluster2_pred_ent.pkl'),\n",
    "                emb_path=os.path.join(codebase, 'graphs/001/emb_mtx_with_sccluster2_pred_ent.pkl'),\n",
    "                rel_counts_path=os.path.join(codebase, 'graphs/001/pred_counts.pkl'),\n",
    "                use_knowledge=True, use_embedding=True, refine_obj_cls=False,\n",
    "                class_volume=1.0, with_clean_classifier=True, with_transfer=True, sa=True, config=conf,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:00.326701Z",
     "iopub.status.busy": "2024-04-23T07:56:00.326529Z",
     "iopub.status.idle": "2024-04-23T07:56:00.352609Z",
     "shell.execute_reply": "2024-04-23T07:56:00.352008Z",
     "shell.execute_reply.started": "2024-04-23T07:56:00.326686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the detector\n",
    "for n, param in detector.detector.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:00.353440Z",
     "iopub.status.busy": "2024-04-23T07:56:00.353286Z",
     "iopub.status.idle": "2024-04-23T07:56:00.375692Z",
     "shell.execute_reply": "2024-04-23T07:56:00.375072Z",
     "shell.execute_reply.started": "2024-04-23T07:56:00.353425Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from apex.optimizers import FusedAdam, FusedSGD\n",
    "from torch import optim\n",
    "\n",
    "def get_optim(lr):\n",
    "    # Lower the learning rate on the VGG fully connected layers by 1/10th. It's a hack, but it helps\n",
    "    # stabilize the models.\n",
    "    fc_params = [p for n,p in detector.named_parameters() if (n.startswith('roi_fmap') or 'clean' in n) and p.requires_grad]\n",
    "    non_fc_params = [p for n,p in detector.named_parameters() if not (n.startswith('roi_fmap') or 'clean' in n) and p.requires_grad]\n",
    "    params = [{'params': fc_params, 'lr': lr / 10.0}, {'params': non_fc_params}]\n",
    "    # params = [p for n,p in detector.named_parameters() if p.requires_grad]\n",
    "\n",
    "    if conf.adam:\n",
    "        optimizer = FusedAdam(params, weight_decay=conf.adamwd, lr=lr, eps=1e-3)\n",
    "        # optimizer = optim.Adam(params, weight_decay=conf.adamwd, lr=lr, eps=1e-3)\n",
    "    else:\n",
    "        optimizer = FusedSGD(params, weight_decay=conf.l2, lr=lr, momentum=0.9)\n",
    "        # optimizer = optim.SGD(params, weight_decay=conf.l2, lr=lr, momentum=0.9)\n",
    "\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.1,\n",
    "    #                               verbose=True, threshold=0.0001, threshold_mode='abs', cooldown=1)\n",
    "    return optimizer #, scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:00.376462Z",
     "iopub.status.busy": "2024-04-23T07:56:00.376309Z",
     "iopub.status.idle": "2024-04-23T07:56:00.618326Z",
     "shell.execute_reply": "2024-04-23T07:56:00.617733Z",
     "shell.execute_reply.started": "2024-04-23T07:56:00.376447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the confusion matrix\n",
    "from lib.my_util import adj_normalize\n",
    "initial_conf_matrix = np.load(conf.MODEL.CONF_MAT_FREQ_TRAIN)\n",
    "initial_conf_matrix[0, :] = 0.0\n",
    "initial_conf_matrix[:, 0] = 0.0\n",
    "initial_conf_matrix[0, 0] = 1.0\n",
    "initial_conf_matrix = initial_conf_matrix / (initial_conf_matrix.sum(-1)[:, None] + 1e-8)\n",
    "initial_conf_matrix = adj_normalize(initial_conf_matrix)\n",
    "np.save('/output/data/misc/conf_mat_updated.npy', initial_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:00.619117Z",
     "iopub.status.busy": "2024-04-23T07:56:00.618959Z",
     "iopub.status.idle": "2024-04-23T07:56:01.682499Z",
     "shell.execute_reply": "2024-04-23T07:56:01.681776Z",
     "shell.execute_reply.started": "2024-04-23T07:56:00.619103Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt = torch.load(conf.ckpt)\n",
    "optimistic_restore(detector, ckpt['state_dict'], skip_clean=False)\n",
    "detector.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:01.683498Z",
     "iopub.status.busy": "2024-04-23T07:56:01.683303Z",
     "iopub.status.idle": "2024-04-23T07:56:01.708015Z",
     "shell.execute_reply": "2024-04-23T07:56:01.707499Z",
     "shell.execute_reply.started": "2024-04-23T07:56:01.683482Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time as time_time\n",
    "def train_epoch(epoch_num):\n",
    "    detector.train()\n",
    "    tr = []\n",
    "    start = time_time()\n",
    "    prog_bar = tqdm(enumerate(train_loader), total=int(len(train)/train_loader.batch_size))\n",
    "    for b, batch in prog_bar:\n",
    "        # print(train_batch(batch, verbose=b % (conf.print_interval*10) == 0))\n",
    "        result, loss_dict = train_batch(batch, verbose=b % (conf.print_interval*10) == 0)\n",
    "        tr.append(loss_dict)\n",
    "        '''\n",
    "        if b % 100 == 0:\n",
    "            print(loss_pd)\n",
    "            gt = result.rel_labels[:,3].data.cpu().numpy()\n",
    "            out = result.rel_dists.data.cpu().numpy()\n",
    "            ind = np.where(gt)[0]\n",
    "            print(gt[ind])\n",
    "            print(np.argmax(out[ind], 1))\n",
    "            print(np.argmax(out[ind, 1:], 1) + 1)\n",
    "        '''\n",
    "\n",
    "        if b % conf.print_interval == 0 and b >= conf.print_interval:\n",
    "#             mn = pd.DataFrame([pd.Series(dicty) for dicty in tr[-conf.print_interval:]]).mean(1)\n",
    "            mn = pd.DataFrame(tr[-conf.print_interval:]).mean(axis=0)\n",
    "            time_per_batch = (time_time() - start) / conf.print_interval\n",
    "            write(\"\\ne{:2d}b{:5d}/{:5d} {:.3f}s/batch, {:.1f}m/epoch\".format(\n",
    "                epoch_num, b, len(train_loader), time_per_batch, len(train_loader) * time_per_batch / 60))\n",
    "            write(mn.to_string())\n",
    "            write('-----------')\n",
    "            start = time_time()\n",
    "    return pd.DataFrame(tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:01.708953Z",
     "iopub.status.busy": "2024-04-23T07:56:01.708793Z",
     "iopub.status.idle": "2024-04-23T07:56:01.732318Z",
     "shell.execute_reply": "2024-04-23T07:56:01.731743Z",
     "shell.execute_reply.started": "2024-04-23T07:56:01.708939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "def train_batch(b, verbose=False):\n",
    "    \"\"\"\n",
    "    :param b: contains:\n",
    "          :param imgs: the image, [batch_size, 3, IM_SIZE, IM_SIZE]\n",
    "          :param all_anchors: [num_anchors, 4] the boxes of all anchors that we'll be using\n",
    "          :param all_anchor_inds: [num_anchors, 2] array of the indices into the concatenated\n",
    "                                  RPN feature vector that give us all_anchors,\n",
    "                                  each one (img_ind, fpn_idx)\n",
    "          :param im_sizes: a [batch_size, 4] numpy array of (h, w, scale, num_good_anchors) for each image.\n",
    "\n",
    "          :param num_anchors_per_img: int, number of anchors in total over the feature pyramid per img\n",
    "\n",
    "          Training parameters:\n",
    "          :param train_anchor_inds: a [num_train, 5] array of indices for the anchors that will\n",
    "                                    be used to compute the training loss (img_ind, fpn_idx)\n",
    "          :param gt_boxes: [num_gt, 4] GT boxes over the batch.\n",
    "          :param gt_classes: [num_gt, 2] gt boxes where each one is (img_id, class)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        result = detector[b]\n",
    "        loss_class = detector.obj_loss(result)\n",
    "        loss_rel = detector.rel_loss(result)\n",
    "        loss_scpred = detector.scpred_loss(result)\n",
    "\n",
    "        loss = loss_class + loss_rel + loss_scpred\n",
    "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        scaled_loss.backward()\n",
    "    clip_grad_norm(\n",
    "        [(n, p) for n, p in detector.named_parameters() if p.grad is not None],\n",
    "        max_norm=conf.clip, verbose=verbose, clip=True)\n",
    "    optimizer.step()\n",
    "    return result, {\n",
    "          'loss_class': float(loss_class),\n",
    "          'loss_rel': float(loss_rel),\n",
    "          'loss_scpred': float(loss_scpred),\n",
    "          'loss_total': float(loss),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:01.733108Z",
     "iopub.status.busy": "2024-04-23T07:56:01.732946Z",
     "iopub.status.idle": "2024-04-23T07:56:01.756661Z",
     "shell.execute_reply": "2024-04-23T07:56:01.756154Z",
     "shell.execute_reply.started": "2024-04-23T07:56:01.733086Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import no_grad as torch_no_grad\n",
    "from tqdm import tqdm\n",
    "\n",
    "def val_epoch():\n",
    "    detector.eval()\n",
    "    evaluator_list = [] # for calculating recall of each relationship except no relationship\n",
    "    evaluator_multiple_preds_list = []\n",
    "    for index, name in enumerate(ind_to_predicates):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        evaluator_list.append((index, name, BasicSceneGraphEvaluator.all_modes()))\n",
    "        evaluator_multiple_preds_list.append((index, name, BasicSceneGraphEvaluator.all_modes(multiple_preds=True)))\n",
    "    evaluator = BasicSceneGraphEvaluator.all_modes() # for calculating recall\n",
    "    evaluator_multiple_preds = BasicSceneGraphEvaluator.all_modes(multiple_preds=True)\n",
    "\n",
    "    prog_bar = tqdm(enumerate(val_loader), total=int(len(val)/val_loader.batch_size))\n",
    "\n",
    "    with torch_no_grad():\n",
    "        for val_b, batch in prog_bar:\n",
    "            val_batch(conf.num_gpus * val_b, batch, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list)\n",
    "\n",
    "    recall = evaluator[conf.mode].print_stats()\n",
    "    recall_mp = evaluator_multiple_preds[conf.mode].print_stats()\n",
    "\n",
    "    mean_recall = calculate_mR_from_evaluator_list(evaluator_list, conf.mode)\n",
    "    mean_recall_mp = calculate_mR_from_evaluator_list(evaluator_multiple_preds_list, conf.mode, multiple_preds=True)\n",
    "\n",
    "    detector.train()\n",
    "    return recall, recall_mp, mean_recall, mean_recall_mp\n",
    "\n",
    "def val_batch(batch_num, b, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list):\n",
    "    with autocast():\n",
    "        det_res = detector[b]\n",
    "    if conf.num_gpus == 1:\n",
    "        det_res = [det_res]\n",
    "\n",
    "    for i, (boxes_i, objs_i, obj_scores_i, rels_i, pred_scores_i) in enumerate(det_res):\n",
    "        gt_entry = {\n",
    "            'gt_classes': val.gt_classes[batch_num + i].copy(),\n",
    "            'gt_relations': val.relationships[batch_num + i].copy(),\n",
    "            'gt_boxes': val.gt_boxes[batch_num + i].copy(),\n",
    "        }\n",
    "        assert np.all(objs_i[rels_i[:, 0]] > 0) and np.all(objs_i[rels_i[:, 1]] > 0)\n",
    "\n",
    "        pred_entry = {\n",
    "            'pred_boxes': boxes_i * BOX_SCALE/IM_SCALE,\n",
    "            'pred_classes': objs_i,\n",
    "            'pred_rel_inds': rels_i,\n",
    "            'obj_scores': obj_scores_i,\n",
    "            'rel_scores': pred_scores_i,  # hack for now.\n",
    "        }\n",
    "\n",
    "        eval_entry(conf.mode, gt_entry, pred_entry, evaluator, evaluator_multiple_preds,\n",
    "                   evaluator_list, evaluator_multiple_preds_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:01.757496Z",
     "iopub.status.busy": "2024-04-23T07:56:01.757342Z",
     "iopub.status.idle": "2024-04-23T07:56:01.779953Z",
     "shell.execute_reply": "2024-04-23T07:56:01.779451Z",
     "shell.execute_reply.started": "2024-04-23T07:56:01.757482Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_evaluate():\n",
    "    detector.eval()\n",
    "    evaluator_list = [] # for calculating recall of each relationship except no relationship\n",
    "    evaluator_multiple_preds_list = []\n",
    "    for index, name in enumerate(ind_to_predicates):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        evaluator_list.append((index, name, BasicSceneGraphEvaluator.all_modes()))\n",
    "        evaluator_multiple_preds_list.append((index, name, BasicSceneGraphEvaluator.all_modes(multiple_preds=True)))\n",
    "    evaluator = BasicSceneGraphEvaluator.all_modes() # for calculating recall\n",
    "    evaluator_multiple_preds = BasicSceneGraphEvaluator.all_modes(multiple_preds=True)\n",
    "\n",
    "    prog_bar = tqdm(enumerate(train_full_loader), total=int(len(train_full)/train_full_loader.batch_size))\n",
    "\n",
    "    with torch_no_grad():\n",
    "        for train_full_b, batch in prog_bar:\n",
    "            train_full_batch(conf.num_gpus * train_full_b, batch, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list)\n",
    "            if train_full_b == 10000: # For efficiency, only evaluate 10000 batches\n",
    "                break\n",
    "    confusion_matrix = evaluator[conf.mode].result_dict['predicate_confusion_matrix']\n",
    "    detector.train()\n",
    "    return confusion_matrix\n",
    "\n",
    "def train_full_batch(batch_num, b, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list):\n",
    "    with autocast():\n",
    "        det_res = detector[b]\n",
    "    if conf.num_gpus == 1:\n",
    "        det_res = [det_res]\n",
    "\n",
    "    for i, (boxes_i, objs_i, obj_scores_i, rels_i, pred_scores_i) in enumerate(det_res):\n",
    "        gt_entry = {\n",
    "            'gt_classes': train_full.gt_classes[batch_num + i].copy(),\n",
    "            'gt_relations': train_full.relationships[batch_num + i].copy(),\n",
    "            'gt_boxes': train_full.gt_boxes[batch_num + i].copy(),\n",
    "        }\n",
    "        assert np.all(objs_i[rels_i[:, 0]] > 0) and np.all(objs_i[rels_i[:, 1]] > 0)\n",
    "\n",
    "        pred_entry = {\n",
    "            'pred_boxes': boxes_i * BOX_SCALE/IM_SCALE,\n",
    "            'pred_classes': objs_i,\n",
    "            'pred_rel_inds': rels_i,\n",
    "            'obj_scores': obj_scores_i,\n",
    "            'rel_scores': pred_scores_i,  # hack for now.\n",
    "        }\n",
    "\n",
    "        eval_entry(conf.mode, gt_entry, pred_entry, evaluator, evaluator_multiple_preds,\n",
    "                   evaluator_list, evaluator_multiple_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T07:56:01.782343Z",
     "iopub.status.busy": "2024-04-23T07:56:01.782184Z",
     "iopub.status.idle": "2024-04-23T08:19:45.855637Z",
     "shell.execute_reply": "2024-04-23T08:19:45.854860Z",
     "shell.execute_reply.started": "2024-04-23T07:56:01.782330Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "alpha = 0.9\n",
    "optimizer = get_optim(conf.lr * conf.num_gpus * conf.batch_size)\n",
    "detector, optimizer = amp.initialize(detector, optimizer, opt_level=\"O0\")\n",
    "\n",
    "start_epoch = 0\n",
    "end_epoch = 20\n",
    "\n",
    "conf_matrix_list = []\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        print('Evaluating new confusion matrix...')\n",
    "        conf_matrix = train_evaluate()\n",
    "        conf_matrix[0, :] = 0.0\n",
    "        conf_matrix[:, 0] = 0.0\n",
    "        conf_matrix[0, 0] = 1.0\n",
    "        conf_matrix = conf_matrix / (conf_matrix.sum(-1)[:, None] + 1e-8)\n",
    "        conf_matrix = adj_normalize(conf_matrix)\n",
    "        conf_matrix_list.append(conf_matrix)\n",
    "\n",
    "        conf_matrix_old = np.load('/output/data/misc/conf_mat_updated.npy')\n",
    "        conf_matrix_new = conf_matrix_old * alpha + conf_matrix * (1 - alpha)\n",
    "        np.save('/output/data/misc/conf_mat_updated.npy', conf_matrix_new)\n",
    "        np.save('/output/data/misc/conf/conf_mat_updated_{}.npy'.format(epoch), conf_matrix_new)\n",
    "\n",
    "    write(f'epoch = {epoch}')\n",
    "    if epoch != 0 and epoch % 10 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] /= 10\n",
    "\n",
    "    rez = train_epoch(epoch)\n",
    "    losses_mean_epoch = rez.mean(axis=0)\n",
    "    losses_mean_epoch_class = losses_mean_epoch['loss_class']\n",
    "    losses_mean_epoch_rel = losses_mean_epoch['loss_rel']\n",
    "    losses_mean_epoch_total = losses_mean_epoch['loss_total']\n",
    "    write(\"overall{:2d}: ({:.3f})\\n{}\".format(epoch, losses_mean_epoch_total, losses_mean_epoch))\n",
    "\n",
    "    if conf.save_dir is not None:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': detector.state_dict(), #{k:v for k,v in detector.state_dict().items() if not k.startswith('detector.')},\n",
    "            # 'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(conf.save_dir, '{}-{}.tar'.format('vgrel', epoch)))\n",
    "        # noinspection PyPackageRequirements\n",
    "        print(os.path.join(conf.save_dir, '{}-{}.tar'.format('vgrel', epoch)))\n",
    "\n",
    "    recall, recall_mp, mean_recall, mean_recall_mp = val_epoch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiker-sgg",
   "language": "python",
   "name": "hiker-sgg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
